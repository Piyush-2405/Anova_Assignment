{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb67c8e2-9994-4f62-a8fc-d1959974f77a",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2bfa9f-7e41-4257-b2ae-0ea34e244379",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare means of two or more groups to determine if there are significant differences between them. However, ANOVA comes with certain assumptions that need to be met in order for its results to be valid and reliable. Violating these assumptions can lead to incorrect or misleading conclusions. The main assumptions of ANOVA include:\n",
    "\n",
    "Independence: Observations within each group are assumed to be independent of each other. This means that the values of one observation do not influence the values of other observations within the same group.\n",
    "\n",
    "Normality: The data within each group are assumed to follow a normal distribution. This assumption is particularly important when the group sizes are small. Deviations from normality can affect the accuracy of p-values and confidence intervals.\n",
    "\n",
    "Homogeneity of Variance (Homoscedasticity): The variances of the groups are assumed to be approximately equal. In other words, the spread of the data points within each group should be similar across all groups.\n",
    "\n",
    "Random Sampling: The data should be collected using a random sampling method from the population of interest. This assumption ensures that the sample is representative of the population.\n",
    "\n",
    "Now, let's consider some examples of violations for each of these assumptions:\n",
    "\n",
    "Independence:\n",
    "\n",
    "Violation Example: In a study measuring the effectiveness of a new teaching method, a teacher uses the method on multiple classes. If the teacher shares teaching strategies among the classes, the independence assumption could be violated.\n",
    "Normality:\n",
    "\n",
    "Violation Example: In an ANOVA examining the test scores of students from different schools, if the test scores within each school's group are not normally distributed, it could impact the ANOVA results. This might occur if one school's scores are skewed while others are normally distributed.\n",
    "Homogeneity of Variance:\n",
    "\n",
    "Violation Example: Consider an ANOVA comparing the yields of three different fertilizers. If the variance of the yield data for one fertilizer is much larger than the variances of the other fertilizers, the assumption of homogeneity of variance could be violated.\n",
    "Random Sampling:\n",
    "\n",
    "Violation Example: In a study comparing income levels of different age groups, if the researcher selects participants non-randomly (e.g., based on convenience sampling), the assumption of random sampling might be violated, potentially biasing the results.\n",
    "It's important to note that ANOVA is relatively robust to violations of assumptions, especially when sample sizes are large. However, when violations are severe, the results might not be trustworthy. In such cases, alternative non-parametric tests or transformations of the data might be considered. It's also a good practice to visually inspect the data using plots like histograms, box plots, and normal probability plots to assess the assumptions before relying on ANOVA results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f666b7-eaad-4b48-bac6-40620401b0d7",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f274a16a-4e26-4f64-9e5e-aef9df2ba173",
   "metadata": {},
   "source": [
    "There are three main types of Analysis of Variance (ANOVA) that are used in different situations to compare means across multiple groups:\n",
    "\n",
    "1.One-Way ANOVA:\n",
    "\n",
    "Situation: One-Way ANOVA is used when you have one categorical independent variable (also called a factor) with three or more levels (groups) and you want to compare the means of a continuous dependent variable across these groups.\n",
    "Example: You might use One-Way ANOVA to compare the average scores of students from different schools based on a single teaching method.\n",
    "\n",
    "2.Two-Way ANOVA:\n",
    "\n",
    "Situation: Two-Way ANOVA is used when you have two categorical independent variables (factors) and you want to assess their main effects and interactions on a continuous dependent variable.\n",
    "Example: Consider a study that examines the effects of both gender and diet on weight loss. Two-Way ANOVA would allow you to investigate the impact of gender, diet, and the interaction between them on weight loss.\n",
    "\n",
    "3.Repeated Measures ANOVA:\n",
    "\n",
    "Situation: Repeated Measures ANOVA is used when you have a single group of participants and you measure the same dependent variable at multiple time points or under different conditions. This allows you to examine changes within the same group over time or across conditions.\n",
    "Example: If you're investigating the effectiveness of a new drug over multiple weeks, you could use Repeated Measures ANOVA to analyze how the drug affects a certain health parameter at different time points.\n",
    "\n",
    "Each type of ANOVA serves a specific purpose based on the structure of your data and research design. It's important to choose the appropriate type of ANOVA based on the factors and variables you are working with in order to draw valid and meaningful conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1cedaa-9528-480a-818d-3d347410de01",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8bbcb1-92e4-4215-89bf-317955696f5e",
   "metadata": {},
   "source": [
    "The partitioning of variance is a fundamental concept in Analysis of Variance (ANOVA) that involves breaking down the total variability observed in a dataset into different components associated with various sources of variation. Understanding this concept is crucial because it allows us to quantify and assess the contributions of different factors to the overall variability in the data. This, in turn, helps us determine whether the observed differences between groups are statistically significant and meaningful or if they could have occurred due to random chance.\n",
    "\n",
    "In ANOVA, the total variability in the data is decomposed into two main components:\n",
    "\n",
    "1.Between-Group Variability (Treatment Variability): This component of variance represents the differences in means among the groups being compared. It measures how much the group means deviate from the overall mean. If the between-group variability is significantly larger than what you would expect by chance, it suggests that there are real differences between the groups.\n",
    "\n",
    "2.Within-Group Variability (Error Variability): This component of variance accounts for the variation within each group. It measures how much individual data points within each group deviate from their group's mean. Larger within-group variability indicates greater heterogeneity within groups.\n",
    "\n",
    "The key idea in ANOVA is that if the between-group variability is much larger than the within-group variability, it suggests that the differences observed between the group means are not likely due to random variation but rather indicate some systematic effect. This provides evidence to reject the null hypothesis, which states that there are no significant differences among the group means.\n",
    "\n",
    "Mathematically, the total variability (Total Sum of Squares, or SST) can be decomposed as follows:\n",
    "\n",
    "Total Variability (SST) = Between-Group Variability (SSB) + Within-Group Variability (SSE)\n",
    "\n",
    "The ratio of the between-group variability to the within-group variability is used to calculate the F-statistic, which is then compared to a critical value from the F-distribution to determine whether the group means are significantly different. This is the basis for hypothesis testing in ANOVA.\n",
    "\n",
    "Understanding the partitioning of variance helps researchers grasp the mechanics of ANOVA and interpret its results correctly. It's essential for making informed decisions about the significance of observed differences and the validity of conclusions drawn from the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ffa31f-3e39-447f-99d7-e36058748007",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd27cf8-a93f-4b9a-a450-a0c764033f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_way_anova(data):\n",
    "  \"\"\"\n",
    "  Calculates the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA.\n",
    "\n",
    "  Args:\n",
    "    data: A list of lists, where each inner list contains the data for one group.\n",
    "\n",
    "  Returns:\n",
    "    A tuple of (SST, SSE, SSR).\n",
    "  \"\"\"\n",
    "\n",
    "  n = len(data)\n",
    "  k = len(data[0])\n",
    "  x_bar = np.mean(data)\n",
    "\n",
    "  # Calculate the total sum of squares\n",
    "  SST = np.sum((x - x_bar)**2 for x in np.concatenate(data))\n",
    "\n",
    "  # Calculate the explained sum of squares\n",
    "  SSE = 0\n",
    "  for group_data in data:\n",
    "     group_mean = np.mean(group_data)\n",
    "     SSE += np.sum((x - group_mean)**2 for x in group_data)\n",
    "\n",
    "  # Calculate the residual sum of squares\n",
    "  SSR = SST - SSE\n",
    "\n",
    "  return SST, SSE, SSR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4363701c-48bb-4684-9761-722f154bd970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 60.0\n",
      "SSE: 6.0\n",
      "SSR: 54.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84/1381828223.py:19: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  SST = np.sum((x - x_bar)**2 for x in np.concatenate(data))\n",
      "/tmp/ipykernel_84/1381828223.py:25: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  SSE += np.sum((x - group_mean)**2 for x in group_data)\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "\n",
    "SST, SSE, SSR = one_way_anova(data)\n",
    "\n",
    "print(\"SST:\", SST)\n",
    "print(\"SSE:\", SSE)\n",
    "print(\"SSR:\", SSR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c1d5bc-30c1-4567-bedd-4a6c820d6c52",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1491e8d-cbbc-4476-b12d-e069aacca5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def two_way_anova(data):\n",
    "  \n",
    "\n",
    "  n = len(data)\n",
    "  k = len(data[0])\n",
    "  l = len(data[0][0])\n",
    "\n",
    "  # Calculate the grand mean\n",
    "  grand_mean = np.mean(np.concatenate(data))\n",
    "\n",
    "  # Calculate the A effect\n",
    "  A_effect = 0\n",
    "  for group_data in data:\n",
    "    A_effect += np.sum((x - grand_mean)**2 for x in group_data)\n",
    "  A_effect /= (n - 1)\n",
    "\n",
    "  # Calculate the B effect\n",
    "  B_effect = 0\n",
    "  for i in range(k):\n",
    "    B_effect += np.sum((x - grand_mean)**2 for x in [row[i] for row in data])\n",
    "  B_effect /= (k - 1)\n",
    "\n",
    "  # Calculate the AB interaction effect\n",
    "  AB_interaction = 0\n",
    "  for i in range(k):\n",
    "    for j in range(l):\n",
    "      AB_interaction += np.sum((data[i][j] - grand_mean)**2)\n",
    "  AB_interaction /= (n - 1)\n",
    "\n",
    "  return A_effect, B_effect, AB_interaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b64412a-c14f-47e1-bd72-0dce7e9fbf8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m], [\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m]]\n\u001b[0;32m----> 3\u001b[0m A_effect, B_effect, AB_interaction \u001b[38;5;241m=\u001b[39m \u001b[43mtwo_way_anova\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA effect:\u001b[39m\u001b[38;5;124m\"\u001b[39m, A_effect)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB effect:\u001b[39m\u001b[38;5;124m\"\u001b[39m, B_effect)\n",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m, in \u001b[0;36mtwo_way_anova\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     14\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[1;32m     15\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 16\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate the grand mean\u001b[39;00m\n\u001b[1;32m     19\u001b[0m grand_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mconcatenate(data))\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "\n",
    "A_effect, B_effect, AB_interaction = two_way_anova(data)\n",
    "\n",
    "print(\"A effect:\", A_effect)\n",
    "print(\"B effect:\", B_effect)\n",
    "print(\"AB interaction:\", AB_interaction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e900326c-0007-40a2-be8a-74c8cd0a6bc9",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fa2da2-568f-41b5-a154-018cb6e4d9f3",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic is used to test whether the means of different groups are significantly different from each other. The p-value associated with the F-statistic helps you determine the statistical significance of the observed differences. Here's how to interpret the results based on the given values:\n",
    "\n",
    "F-Statistic: The F-statistic value of 5.23 is a measure of the ratio of the between-group variability to the within-group variability. It indicates the extent to which the group means differ from the overall mean, relative to the variability within each group.\n",
    "\n",
    "P-Value: The p-value of 0.02 is the probability of observing an F-statistic as extreme as the one you obtained (or more extreme) under the assumption that there are no real differences among the group means (null hypothesis). A smaller p-value suggests stronger evidence against the null hypothesis.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "Since the p-value (0.02) is less than the commonly used significance level of 0.05 (or 5%), you have statistical evidence to reject the null hypothesis. This means that the differences observed between the group means are unlikely to have occurred due to random chance alone. In other words, the data provide enough evidence to conclude that there are statistically significant differences between at least some of the groups.\n",
    "\n",
    "However, the p-value does not directly tell you which specific groups are different from each other. To identify which groups are different, you might need to conduct post hoc tests (such as Tukey's HSD, Bonferroni, or Sidak tests) or perform pairwise comparisons with appropriate adjustments for multiple comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e14914b-aa0b-4f03-9ca7-04f7ab947ad7",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84c5e25-3c42-471f-bd60-316eb6320374",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA is an important consideration to ensure accurate and reliable results. Missing data can arise due to various reasons such as participant dropout, technical errors, or incomplete responses. Different methods can be used to handle missing data, but the choice of method can impact the validity and generalizability of your results. Here are some common approaches and their potential consequences:\n",
    "\n",
    "1.Complete Case Analysis (Listwise Deletion):\n",
    "\n",
    "Approach: This method involves excluding cases (participants) with missing data from the analysis. Only complete cases are used in the analysis.\n",
    "Consequences: This approach can lead to biased results if the missing data are not missing completely at random (MCAR). It can reduce the sample size, potentially reducing the power of the analysis. Moreover, if the missing data are related to the variable being studied, it can lead to biased parameter estimates and standard errors.\n",
    "\n",
    "2.Mean Imputation:\n",
    "\n",
    "Approach: For each missing data point, replace it with the mean value of the observed data for that variable.\n",
    "Consequences: While mean imputation is simple, it can distort the distribution of the variable, underestimate the variability, and produce artificially narrow confidence intervals. It can also attenuate the relationships between variables, leading to biased estimates and incorrect standard errors.\n",
    "\n",
    "3.Last Observation Carried Forward (LOCF):\n",
    "\n",
    "Approach: Replace missing values with the last observed value for that variable.\n",
    "Consequences: LOCF assumes that the missing data remain constant over time, which might not be valid. This approach can lead to inaccurate estimates of change or variability.\n",
    "\n",
    "4.Linear Interpolation:\n",
    "\n",
    "Approach: Estimate missing values based on the linear relationship between adjacent observed values.\n",
    "Consequences: Linear interpolation assumes a linear relationship between observations, which may not be appropriate. It can lead to biased results if the underlying relationships are nonlinear.\n",
    "\n",
    "5.Multiple Imputation:\n",
    "\n",
    "Approach: Generate multiple sets of plausible values to replace missing data, creating multiple \"complete\" datasets. Analyze each dataset separately and combine the results.\n",
    "Consequences: Multiple imputation provides more accurate parameter estimates and standard errors compared to single imputation methods. However, it requires assumptions about the missing data mechanism and might be computationally intensive.\n",
    "\n",
    "6.Model-Based Methods:\n",
    "\n",
    "Approach: Fit a model to the observed data and use the model to estimate missing values.\n",
    "Consequences: Model-based methods can provide accurate estimates if the model assumptions are met. However, they can also introduce bias if the model is misspecified.\n",
    "\n",
    "The choice of method should be based on the characteristics of your data and the underlying reasons for missingness. It's recommended to conduct sensitivity analyses, compare results using different methods, and report the potential impact of missing data handling on the conclusions drawn from the analysis. Ultimately, transparency and careful consideration of the missing data approach are essential for trustworthy results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7b3f0e-244b-4ce6-b0db-5ced7ff40c3b",
   "metadata": {},
   "source": [
    "Post-hoc tests are used after conducting an ANOVA to determine which specific group differences are statistically significant when a significant overall effect is found. ANOVA can tell you that there are differences between at least two groups, but it doesn't specify which groups are different from each other. Post-hoc tests help to identify these pairwise differences. Here are some common post-hoc tests and when you might use each one:\n",
    "\n",
    "1.Tukey's Honestly Significant Difference (HSD):\n",
    "\n",
    "When to Use: Tukey's HSD is used when you have a moderate to large sample size and want to compare all possible pairs of group means.\n",
    "Example: In a study comparing the effectiveness of three different medications on blood pressure, after finding a significant overall effect, you can use Tukey's HSD to determine which specific pairs of medications have significantly different effects.\n",
    "\n",
    "2.Bonferroni Correction:\n",
    "\n",
    "When to Use: Bonferroni correction is used when you want to control the familywise error rate (the probability of making at least one Type I error across all comparisons) by adjusting the significance level for each individual comparison.\n",
    "Example: If you are conducting multiple pairwise comparisons after an ANOVA, Bonferroni correction can be useful to maintain a desired overall level of significance while making multiple comparisons.\n",
    "\n",
    "3.Dunn's Test:\n",
    "\n",
    "When to Use: Dunn's test is used when you have a small sample size or unequal group sizes, and you want to compare group means while controlling the Type I error rate.\n",
    "Example: In a psychological study with multiple treatment conditions and a relatively small sample, Dunn's test can be used to perform pairwise comparisons after obtaining a significant ANOVA result.\n",
    "\n",
    "4.Sidak Correction:\n",
    "\n",
    "When to Use: Similar to Bonferroni correction, Sidak correction adjusts the significance level for multiple comparisons. It's often used when the number of comparisons is small.\n",
    "Example: If you have a small number of treatment groups and you want to compare their means after an ANOVA, Sidak correction can be used to adjust the p-values for multiple comparisons.\n",
    "\n",
    "5.Holm's Method:\n",
    "\n",
    "When to Use: Holm's method is a stepwise procedure that adjusts the significance level for multiple comparisons. It controls the familywise error rate while giving more power than Bonferroni correction.\n",
    "Example: In a genetics study, you may want to compare the expression levels of multiple genes across different conditions after an ANOVA. Holm's method can be used to control the overall error rate.\n",
    "\n",
    "When using post-hoc tests, it's important to consider the trade-off between controlling the familywise error rate and maintaining statistical power. The choice of which test to use depends on your research question, sample size, the number of comparisons, and the desired level of control over Type I errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fae08db-57f3-4d47-a332-3982055f980b",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57ae61f6-e45d-468a-ae20-b4c260927c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 24.45494897317441\n",
      "P-value: 6.787038182551511e-10\n",
      "There are significant differences in the mean weight loss between the diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random weight loss data for three diets\n",
    "data_A = np.random.normal(loc=10, scale=2, size=50)  # Diet A\n",
    "data_B = np.random.normal(loc=8, scale=2, size=50)   # Diet B\n",
    "data_C = np.random.normal(loc=7, scale=2, size=50)   # Diet C\n",
    "\n",
    "# Combine the data from all three diets\n",
    "all_data = np.concatenate((data_A, data_B, data_C))\n",
    "\n",
    "# Create a categorical variable to represent the diets\n",
    "diets = np.array(['A'] * 50 + ['B'] * 50 + ['C'] * 50)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(data_A, data_B, data_C)\n",
    "\n",
    "# Print results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "if p_value < 0.05:\n",
    "    print(\"There are significant differences in the mean weight loss between the diets.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in the mean weight loss between the diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d733caa-c702-4193-8845-a6a64eefd83a",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b31c3d38-ba04-4b0b-ad70-9fa93b79ad6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -4.108723928204809\n",
      "P-value: 8.261945608702611e-05\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      " group1   group2   meandiff p-adj  lower   upper  reject\n",
      "--------------------------------------------------------\n",
      "Control Experiment   7.4325 0.0001 3.8427 11.0224   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random test scores for demonstration\n",
    "n_control = 50\n",
    "n_experiment = 50\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=n_control)\n",
    "experiment_scores = np.random.normal(loc=75, scale=10, size=n_experiment)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = pd.DataFrame({'Group': ['Control'] * n_control + ['Experiment'] * n_experiment,\n",
    "                     'Scores': np.concatenate((control_scores, experiment_scores))})\n",
    "\n",
    "# Perform two-sample t-test\n",
    "control_data = data[data['Group'] == 'Control']['Scores']\n",
    "experiment_data = data[data['Group'] == 'Experiment']['Scores']\n",
    "t_statistic, p_value = ttest_ind(control_data, experiment_data)\n",
    "\n",
    "# Print t-test results\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Perform Tukey's HSD post-hoc test\n",
    "tukey_results = pairwise_tukeyhsd(data['Scores'], data['Group'])\n",
    "\n",
    "# Print Tukey's HSD results\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799c42f2-4323-4a63-9ef7-72f3f3398081",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3f4101a-4a3e-49b9-a739-4511e91ba806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Mixed Linear Model Regression Results\n",
      "==============================================================\n",
      "Model:               MixedLM   Dependent Variable:   Sales    \n",
      "No. Observations:    90        Method:               REML     \n",
      "No. Groups:          30        Scale:                1593.6888\n",
      "Min. group size:     3         Log-Likelihood:       -454.9819\n",
      "Max. group size:     3         Converged:            Yes      \n",
      "Mean group size:     3.0                                      \n",
      "--------------------------------------------------------------\n",
      "                  Coef.  Std.Err.   z    P>|z|  [0.025  0.975]\n",
      "--------------------------------------------------------------\n",
      "Intercept        123.633    7.849 15.752 0.000 108.250 139.016\n",
      "Store[T.Store B]  -3.933   10.308 -0.382 0.703 -24.136  16.269\n",
      "Store[T.Store C]  -4.467   10.308 -0.433 0.665 -24.669  15.736\n",
      "Group Var        254.299    6.329                             \n",
      "==============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import mixedlm\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random data for demonstration\n",
    "n_days = 30\n",
    "n_stores = 3\n",
    "\n",
    "# Create a DataFrame with store, day, and sales columns\n",
    "data = pd.DataFrame({\n",
    "    'Store': np.repeat(['Store A', 'Store B', 'Store C'], n_days),\n",
    "    'Day': np.tile(range(1, n_days + 1), n_stores),\n",
    "    'Sales': np.random.randint(50, 200, size=n_days * n_stores)\n",
    "})\n",
    "\n",
    "# Fit a mixed-effects ANOVA model\n",
    "model_formula = 'Sales ~ Store'\n",
    "mixed_model = mixedlm(model_formula, data=data, groups=data['Day'])\n",
    "result = mixed_model.fit()\n",
    "\n",
    "# Print mixed-effects ANOVA results\n",
    "print(result.summary())\n",
    "\n",
    "# If results are significant, you can consider post-hoc tests or pairwise comparisons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b3bff7-2a3a-440d-95a5-c7fb8de11271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
